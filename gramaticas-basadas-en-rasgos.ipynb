{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gramáticas basadas en rasgos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Motivaciones para la introducción de rasgos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: justify\">A comienzos de los años ochenta se sabía perfectamente que las gramáticas regulares eran insuficientes para dar cuenta del lenguaje natural y se sabía también que las gramáticas transformacionales eran computacionalmente inadecuadas. Por el momento, los argumentos en contra de las gramáticas independientes de contexto eran más bien conceptuales:</div>\n",
    "\n",
    "- <div style=\"text-align: justify\">eran \"torpes\", ya que para dar cuenta de fenómenos relativamente sencillos como la concordancia y la subcategorización, era necesario recurrir a un número enorme de nodos no categoriales</div>\n",
    "- <div style=\"text-align: justify\">no daban cuenta de la relatedness entre construcciones.</div>\n",
    "\n",
    "\n",
    "Earley [1970](http://ra.adm.cs.cmu.edu/anon/home/anon/usr/ftp/scan/CMU-CS-68-earley.pdf) había demostrado que existía la posibilidad de parsear lenguajes independientes de contexto en tiempos computacionalmente tratables. Esto hizo que las Gramáticas Independientes resultaran nuevamente tentadoras. Para resolver el problema de la \"torpeza\" de las Gramáticas Independientes de Contexto\", los autores empezaron a utilizar una estrategia que, si bien se conocía hacía mucho tiempo (al menos desde Harris 1946, pasando por Harman 1963 y Chomsky 1965), no se había explotado explícitamente: descomponer la información de los nodos no terminales en rasgos. Se creía en aquel momento que este agregado no cambiaba el lenguaje generado por una gramática:\n",
    "\n",
    "<div style=\"text-align: justify\">\"For reasons put very nicely by Halle (1969) with respect to phonology, there is an exact equivalence between generative systems that use complex symbols (matrices of distinctive feature specifications) and those that do not. The proof is trivial. Basically, only the way the symbols are interpreted is at issue. A nonterminal symbol [x<sub>1</sub>,x<sub>2</sub>,x<sub>3</sub>..., x<sub>n</sub>], where each xt is some feature specification, can be treated as having internal structure to which statements in the grammar can refer to capture generalizations, or it can be regarded as a calligraphically ornate representation of an atomic symbol distinct from all other symbols\". (Gazdar et al 1985)</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gramáticas basadas en rasgos en la jerarquía de Chomsky\n",
    "\n",
    "<div style=\"text-align: justify\">Supongamos un lenguaje formado solamente por las siguientes cadenas:</div>\n",
    "\n",
    "- ab, aabb, aaabbb, aaaabbbb\n",
    "\n",
    "<div style=\"text-align: justify\">Las cadenas de este lenguaje siguen un patrón típico de las gramáticas independientes de contexto: tienen recursividad central. Si embargo, puesto que este lenguaje es finito, puede ser generado por un autómata de estados finitos o por una expresión regular:</div>\n",
    "\n",
    "- a(a(ab)?b)?b\n",
    "\n",
    "<div style=\"text-align: justify\">Es decir que, si nos atenemos a un lenguaje finito, podemos emular operaciones típicas de lenguajes más complejos utilizando más estados en el autómata o más símbolos no terminales en una gramática regular.</div>\n",
    "\n",
    "<div style=\"text-align: justify\">Del mismo modo, una gramática independiente de contexto puede emular lo que típicamente hace una gramática con rasgos extendiendo su número de símbolos no terminales:</div>\n",
    "\n",
    "- N[Gen=fem, Num=sg, etc.] = NCFSVO\n",
    "\n",
    "<div style=\"text-align: justify\">De un modo similar a lo que pasaba con los autómatas de estados finitos, esto se puede hacer en la medida en que tengamos un número finito de rasgos con un número finito de valores. En cuanto tenemos un número infinito de valores (la recursividad de rasgos, i.e., rasgos complejos, dispara esta posibilidad), se vuelve imposible capturar lo que puede hacer una gramática basada en rasgos mediante una gramática independiente de contexto. En conclusión: se sabe que las gramáticas basadas en rasgos incluyen propiamente a las gramáticas independientes de contexto.</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## La implementación\n",
    "\n",
    "Las gramáticas basadas en rasgos se implementaron en diversos lenguajes. Inicialmente, el más desarrollado fue [PC-PATR](https://software.sil.org/pc-patr/), que actualmente está discontinuado y ya no tiene soporte.\n",
    "\n",
    "A partir de los trabajos de Pereira y Warren (1980, 1983), se fue popularizando también la implementación en [Prolog](https://www.swi-prolog.org/).\n",
    "\n",
    "Para Python se pueden construir gramáticas basadas en rasgos en [NLTK](https://www.nltk.org/book/ch09.html). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PC-PATR\n",
    "\n",
    "PC-PATR se especializó en herramientas para procesamiento del lenguaje natural y en particular, se especializó en ser el lenguaje para implementar diferentes teorías gramaticales. Por esta razón, este lenguaje proveía soporte para implementar reglas típicas de la teoría sintáctica del momento. Esto incluía las siguientes cosas:\n",
    "\n",
    "- Gramáticas de reglas de reescritura\n",
    "- Reglas léxicas\n",
    "- Metarreglas\n",
    "- Postulados de significado\n",
    "- Agregado de rasgos y la operación de unificación.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prolog\n",
    "\n",
    "Prolog se popularizó para procesamiento del lenguaje natural. También en él se implementaron distintas teorías gramaticales. Algunas de las gramáticas que se desarrollaron en él fueron ProfGlot, [Definite Clause Grammars](http://www.pathwayslms.com/swipltuts/dcg/), [ALE](https://www.cs.toronto.edu/~gpenn/ale.html), Gramáticas Minimalistas (ver página de [Stabler](https://linguistics.ucla.edu/people/stabler/coding.html)), la [Gramática de Montague](http://www.sfs.uni-tuebingen.de/~keberle/SemParsing/Slides/slidesPrMS.pdf), [HPSG](http://www.cs.toronto.edu/~gpenn/ale/files/grammars/hpsg.pl), etc. \n",
    "\n",
    "Uno de los motivos que hizo que se utilizara es que es un lenguaje de programación declarativo antes que procedural. Se basa principalmente en la declaración de hechos (facts), que son declaraciones de verdad no condicionadas, y reglas (rules), que son declaraciones de verdad condicionadas. A partir de estos dos tipos de reglas, Prolog hace inferencias y el usuario normalmente interactúa con Prolog haciéndole preguntas de si determinada inferencia tiene lugar o no. Este comportamiento cuadraba perfectamente con el fuerte carácter declarativo antes que procedimental de la teoría lingüística de los años ochenta.\n",
    "\n",
    "Por ejemplo, se le puede preguntar a Prolog cuáles son las cadenas que se pueden generar a partir del nodo s en dcg1.pl\n",
    "\n",
    "`phrase(s, Sentence).`\n",
    "\n",
    "`s(X,[]).`\n",
    "\n",
    "También se le puede preguntar si tal o cual frase es correcta:\n",
    "\n",
    "`phrase(s, [el, lingüista, piensa]).`\n",
    "\n",
    "`s([el, lingüista, piensa],[]).`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FCFG en NLTK\n",
    "\n",
    "Dato importante para no perder tiempo: cuando se modifica una fcfg y se la quiere correr desde la Jupyter, si no se resetea el kernel, sigue corriendo la gramática previa al cambio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "% start S\n",
      "#Adaptado al español de la gramática elaborada por Klein para el libro de NLTK\n",
      "#\n",
      "# ###################\n",
      "# Reglas de la Gramática\n",
      "# ###################\n",
      "# Reescritura de la Raíz\n",
      "S -> NP[NUM=?n] VP[NUM=?n]\n",
      "# Reescritura de NP\n",
      "NP[NUM=?n] -> PropN[NUM=?n] \n",
      "NP[NUM=?n,GEN=?g] -> Det[NUM=?n,GEN=?g] N[NUM=?n,GEN=?g]\n",
      "# Reescritura de VP\n",
      "VP[TENSE=?t, NUM=?n] -> V[TENSE=?t, NUM=?n]\n",
      "# ###################\n",
      "# Léxico\n",
      "# ###################\n",
      "Det[NUM=sg,GEN=masc] -> 'este' | 'el'\n",
      "Det[NUM=pl,GEN=masc] -> 'estos' | 'los'\n",
      "Det[NUM=sg,GEN=fem] -> 'esta' | 'la'\n",
      "Det[NUM=pl,GEN=fem] -> 'estas' | 'las'\n",
      "PropN[NUM=sg]-> 'Cata' | 'Julia' | 'Fede' | 'Fer' | 'Martín' | 'Maca' | 'Vicky' | 'Pablo'\n",
      "N[NUM=sg,GEN=fem] -> 'chica' | 'mujer' | 'persona' | 'criatura'\n",
      "N[NUM=sg,GEN=masc] -> 'chico' | 'hombre' | 'sujeto' \n",
      "N[NUM=pl,GEN=fem] -> 'chicas' | 'mujeres' | 'personas' | 'criaturas'\n",
      "N[NUM=pl,GEN=masc] -> 'chicos' | 'hombres' | 'sujetos' \n",
      "V[TENSE=pres,NUM=sg] -> 'desaparece' | 'camina' | 'muerde' | 'llora' | 'aparece' | 'viene' | 'estornudan'\n",
      "V[TENSE=pres,NUM=pl] -> 'desaparecen' | 'caminan' | 'lloran' | 'muerden' | 'aparecen' | 'vienen' | 'estornudan'\n",
      "V[TENSE=pas,NUM=sg] -> 'desapareció' | 'caminó' | 'mordió' | 'lloraba' | 'apareció' | 'vino' | 'estornudó'\n",
      "V[TENSE=pas,NUM=pl] -> 'desaparecieron' | 'caminaron' | 'mordieron' | 'lloraban' | 'aparecieron' | 'vinieron' | 'estornudaron'\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "\n",
    "nltk.data.show_cfg('Ej1GramaticaDeRasgos.fcfg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|.este.chic.desa.|\n",
      "Leaf Init Rule:\n",
      "|[----]    .    .| [0:1] 'este'\n",
      "|.    [----]    .| [1:2] 'chico'\n",
      "|.    .    [----]| [2:3] 'desaparece'\n",
      "Feature Bottom Up Predict Combine Rule:\n",
      "|[----]    .    .| [0:1] Det[GEN='masc', NUM='sg'] -> 'este' *\n",
      "Feature Bottom Up Predict Combine Rule:\n",
      "|[---->    .    .| [0:1] NP[GEN=?g, NUM=?n] -> Det[GEN=?g, NUM=?n] * N[GEN=?g, NUM=?n] {?g: 'masc', ?n: 'sg'}\n",
      "Feature Bottom Up Predict Combine Rule:\n",
      "|.    [----]    .| [1:2] N[GEN='masc', NUM='sg'] -> 'chico' *\n",
      "Feature Single Edge Fundamental Rule:\n",
      "|[---------]    .| [0:2] NP[GEN='masc', NUM='sg'] -> Det[GEN='masc', NUM='sg'] N[GEN='masc', NUM='sg'] *\n",
      "Feature Bottom Up Predict Combine Rule:\n",
      "|[--------->    .| [0:2] S[] -> NP[NUM=?n] * VP[NUM=?n] {?n: 'sg'}\n",
      "Feature Bottom Up Predict Combine Rule:\n",
      "|.    .    [----]| [2:3] V[NUM='sg', TENSE='pres'] -> 'desaparece' *\n",
      "Feature Bottom Up Predict Combine Rule:\n",
      "|.    .    [----]| [2:3] VP[NUM='sg', TENSE='pres'] -> V[NUM='sg', TENSE='pres'] *\n",
      "Feature Single Edge Fundamental Rule:\n",
      "|[==============]| [0:3] S[] -> NP[NUM='sg'] VP[NUM='sg'] *\n",
      "(S[]\n",
      "  (NP[GEN='masc', NUM='sg']\n",
      "    (Det[GEN='masc', NUM='sg'] este)\n",
      "    (N[GEN='masc', NUM='sg'] chico))\n",
      "  (VP[NUM='sg', TENSE='pres'] (V[NUM='sg', TENSE='pres'] desaparece)))\n"
     ]
    }
   ],
   "source": [
    "tokens = 'este chico desaparece'.split()\n",
    "from nltk import load_parser\n",
    "cp = load_parser('Ej1GramaticaDeRasgos.fcfg', trace=2)\n",
    "for tree in cp.parse(tokens):\n",
    "     print(tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "adjs_freeling = pd.read_csv('freeling/MM.adj.txt', delimiter=' ')\n",
    "adjs_freeling.head(10)\n",
    "#print(adjs_freeling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.data.show_cfg('gram_para_fcfg.fcfg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = 'la gata camina'.split()\n",
    "from nltk import load_parser\n",
    "cp = load_parser('gram_para_fcfg.fcfg', trace=2)\n",
    "for tree in cp.parse(tokens):\n",
    "     print(tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Uso de rasgos para significado"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los rasgos pueden utilizarse a su vez para construir una representación semántica de las oraciones.\n",
    "\n",
    "En semántica formal existe una función particular, que se conoce con el nombre de función interpretación, y que se anota con corchetes dobles. La función interpretación devuelve por cada expresión lingüística su denotación. Las denotaciones pueden ser de dos tipos: \n",
    "\n",
    "- elementos atómicos (típicamente objetos o proposiciones, pero también hay otras ontologías que incluyen mundos posibles, eventos y tiempos, entre otras cosas)\n",
    "- funciones. \n",
    "\n",
    "El uso de rasgos para dar cuenta del significado consiste en que la función denotación sea el valor de un rasgo semántico.\n",
    "\n",
    "Ver [Smith 2004](http://www.inf.ed.ac.uk/teaching/courses/aipp/lecture_slides/11_PS_DCGs.pdf)\n",
    "\n",
    "Puede pedírsele a Prolog que genere las oraciones y los significados que reescriben al nodo no terminal s de acuerdo a la gramática gram_sem,pl.\n",
    "\n",
    "`s(X,Y,[]).`\n",
    "\n",
    "También puede pedírsele que genere la oración correspondiente a determinado significado\n",
    "\n",
    "`s(fumar(juan),Y,[]).`\n",
    "\n",
    "O que devuelva el significado de una oración en particular:\n",
    "\n",
    "`s(X,[juan, fuma],[]).`\n",
    "\n",
    "También se le puede pedir a Prolog que genere las oraciones, los significados y el parseo que reescriben al nodo no terminal s de acuerdo a la gramática gram_parseo_sem.pl\n",
    "\n",
    "`s(X,Y,Z,[]).`\n",
    "\n",
    "Puede reemplazarse cada una de las variables con el valor que querramos para saber el valor de las demás variables. Si se da un valor a todas las variables, Prolog nos devolverá un valor booleano. Por ejemplo:\n",
    "\n",
    "`s(s(n(juan),v(nada)),nadar(juan),[juan, nada],[]).`\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En el [libro de NLTK](https://www.nltk.org/book/ch10.html) y en la [documentación de NLTK](http://nltk.sourceforge.net/doc/en/ch11.html) hay información sobre cómo implementar esto mediante una gramática de rasgos en NLTK.\n",
    "\n",
    "\n",
    "Las funciones equivalen a conjuntos y se expresan en el llamado cálculo lambda. \n",
    "\n",
    "\\x. x fuma\n",
    "\n",
    "Esta es una función que toma un x y devuelve verdadero si x fuma y falso si x no fuma. En términos de conjuntos equivale al conjunto de todos los fumadores (ténicamente equivale al conjunto característico de todos los fumadores, que es el que devuelve verdadero si x fuma y falso si x no fuma).\n",
    "\n",
    "Hay dos operaciones básicas de cálculo lambda que son particularmente relevantes (una tercera no tuvo tanta repercusión en la semántica formal):\n",
    "\n",
    "- Conversión alpha (o reducción alpha): cambiar el nombre de una variable y, conjuntamente, el de todas las variables ligadas con ella.\n",
    "`[\\x. x fuma] = [\\y. y fuma] = [\\z. z fuma] = ...`\n",
    "- Conversión lambda (o reducción beta): cuando combinamos una función con un argumento, eliminar el prefijo lambda y reemplazar todas las ocurrencias de la variable que introduce ese prefijo por el argumento.\n",
    "\n",
    "- `[\\x. x fuma](cata) = cata fuma`\n",
    "- `[\\f. f](\\x. x fuma) = \\x. x fuma`\n",
    "- `[\\f. [\\g. [\\x. g(x)=f(x)=1]]](\\x. x fuma)(\\x. x baila) = [\\x. [\\x. x fuma](x)=[\\x. x baila](x)=1] = [\\x x fuma y x baila]` \n",
    "\n",
    "Las interpretación semántica de las expresiones lingüísticas se da a partir del significado de sus partes y su combinación mediante reglas que dependen de la forma del árbol y de los tipos de las funciones. Las reglas más frecuentes son: \n",
    "\n",
    "- Aplicación funcional: Si un nodo A domina a dos nodos B y C tales que B es una función cuyo dominio incluye a C, entonces [[A]]=[[B]]([[C]])\n",
    "- Modificación de predicados: Si un nodo A domina a dos nodos B y C tales que los dos nodos son funciones que van del dominio de los individuos al dominio de los valores de verdad, entonces [[A]] = \\x. [[B]]=[[C]]=1\n",
    "\n",
    "Las fcfg implementan la función intepretación como valor de un rasgo semántico y reemplazando las reglas que dependen de la forma del árbol directamente por restricciones en las reglas de reescritura. Estas restricciones consisten básicamente en la unificación mediante variables idénticas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "% start S\n",
      "# Grammar Rules\n",
      "S[SEM = <?subj(?vp)>] -> NP[NUM=?n,GEN=?g,SEM=?subj] VP[NUM=?n,GEN=?g,SEM=?vp]\n",
      "NP[NUM=?n,GEN=?g,SEM=<?det(?nom)>] -> Det[NUM=?n,GEN=?g,SEM=?det]  Nom[NUM=?n,GEN=?g,SEM=?nom]\n",
      "NP[LOC=?l,NUM=?n,GEN=?g,SEM=?np] -> PropN[LOC=?l,NUM=?n,GEN=?g,SEM=?np]\n",
      "Nom[NUM=?n,GEN=?g,SEM=?nom] -> N[NUM=?n,GEN=?g,SEM=?nom]\n",
      "VP[NUM=?n,SEM=?v] -> IV[NUM=?n,SEM=?v]\n",
      "VP[NUM=?n,SEM=<?v(?obj)>] -> TV[NUM=?n,SEM=?v] NP[SEM=?obj]\n",
      "VP[NUM=?n,SEM=<?v(?obj,?pp)>] -> DTV[NUM=?n,SEM=?v] NP[SEM=?obj] PP[+A,SEM=?pp]\n",
      "VP[NUM=?n,GEN=?g,SEM=<?v(?a)>] -> VCOP[NUM=?n] A[NUM=?n,GEN=?g,SEM=?a]\n",
      "PP[+A, SEM=?np] -> P[+A] NP[SEM=?np]\n",
      "# Lexical Rules\n",
      "PropN[-LOC,NUM=sg,GEN=masc,SEM=<\\P.P(martin)>] -> 'Martín'\n",
      "PropN[-LOC,NUM=sg,GEN=fem,SEM=<\\P.P(cata)>] -> 'Cata'\n",
      "PropN[-LOC,NUM=sg,GEN=masc,SEM=<\\P.P(fede)>] -> 'Fede'\n",
      "PropN[-LOC,NUM=sg,GEN=masc,SEM=<\\P.P(pablo)>] -> 'Pablo'\n",
      "PropN[-LOC,NUM=sg,GEN=fem,SEM=<\\P.P(julia)>] -> 'Julia'\n",
      "PropN[-LOC,NUM=sg,GEN=masc,SEM=<\\P.P(fer)>] -> 'Fer'\n",
      "PropN[-LOC,NUM=sg,GEN=fem,SEM=<\\P.P(maca)>] -> 'Maca'\n",
      "Det[NUM=sg,GEN=masc,SEM=<\\P Q.exists x.(unico_ind_relevante_en_contexto(x) & P(x) & Q(x))>] -> 'el'\n",
      "Det[NUM=sg,GEN=fem,SEM=<\\P Q.exists x.(unico_ind_relevante_en_contexto(x) & P(x) & Q(x))>] -> 'la'\n",
      "Det[NUM=sg,GEN=masc,SEM=<\\P Q.exists x.(unico_ind_pl_relevante_en_contexto(x) & P(x) & Q(x))>] -> 'los'\n",
      "Det[NUM=sg,GEN=fem,SEM=<\\P Q.exists x.(unico_ind_pl_relevante_en_contexto(x) & P(x) & Q(x))>] -> 'las'\n",
      "Det[NUM=sg,GEN=masc,SEM=<\\P Q.exists x.(P(x) & Q(x))>] -> 'algún'\n",
      "Det[NUM=pl,GEN=masc,SEM=<\\P Q.exists x.(ind_pl(x) & P(x) & Q(x))>] -> 'algunos'\n",
      "Det[NUM=sg,GEN=fem,SEM=<\\P Q.exists x.(P(x) & Q(x))>] -> 'alguna'\n",
      "Det[NUM=pl,GEN=fem,SEM=<\\P Q.exists x.(ind_pl(x) & P(x) & Q(x))>] -> 'algunas'\n",
      "Det[NUM=sg,GEN=masc,SEM=<\\P Q.exists x.(P(x) & Q(x))>] -> 'un'\n",
      "Det[NUM=sg,GEN=fem,SEM=<\\P Q.exists x.(P(x) & Q(x))>] -> 'una'\n",
      "Det[NUM=pl,GEN=masc,SEM=<\\P Q.exists x.(ind_pl(x) & P(x) & Q(x))>] -> 'unos'\n",
      "Det[NUM=pl,GEN=fem,SEM=<\\P Q.exists x.(ind_pl(x) & P(x) & Q(x))>] -> 'unas'\n",
      "N[NUM=sg,GEN=masc,SEM=<\\x.globo(x)>] -> 'globo'\n",
      "N[NUM=pl,GEN=masc,SEM=<\\x.globo(x)>] -> 'globos'\n",
      "N[NUM=sg,GEN=fem,SEM=<\\x.chica(x)>] -> 'chica'\n",
      "N[NUM=sg,GEN=masc,SEM=<\\x.chico(x)>] -> 'chico'\n",
      "N[NUM=sg,GEN=masc,SEM=<\\x.hombre(x)>] -> 'hombre'\n",
      "N[NUM=pl,GEN=masc,SEM=<\\x.hombre(x)>] -> 'hombres'\n",
      "N[NUM=sg,GEN=fem,SEM=<\\x.mujer(x)>] -> 'mujer'\n",
      "N[NUM=pl,GEN=fem,SEM=<\\x.mujer(x)>] -> 'mujeres'\n",
      "N[NUM=sg,GEN=masc,SEM=<\\x.perro(x)>] -> 'perro'\n",
      "N[NUM=pl,GEN=masc,SEM=<\\x.perro(x)>] -> 'perros'\n",
      "N[NUM=sg,GEN=masc,SEM=<\\x.gato(x)>] -> 'gato'\n",
      "N[NUM=pl,GEN=masc,SEM=<\\x.gato(x)>] -> 'gatos'\n",
      "N[NUM=sg,GEN=masc,SEM=<\\x.regalo(x)>] -> 'regalo'\n",
      "N[NUM=pl,GEN=masc,SEM=<\\x.regalo(x)>] -> 'regalos'\n",
      "N[NUM=sg,GEN=masc,SEM=<\\x.paquete(x)>] -> 'paquete'\n",
      "N[NUM=pl,GEN=masc,SEM=<\\x.paquete(x)>] -> 'paquetes'\n",
      "N[NUM=sg,GEN=masc,SEM=<\\x.tabaco(x)>] -> 'tabaco'\n",
      "N[NUM=pl,GEN=masc,SEM=<\\x.cigarrillo(x)>] -> 'cigarrillos'\n",
      "N[NUM=sg,GEN=masc,SEM=<\\x.cigarrillo(x)>] -> 'cigarrillo'\n",
      "N[NUM=sg,GEN=masc,SEM=<\\x.libro(x)>] -> 'libro'\n",
      "N[NUM=pl,GEN=masc,SEM=<\\x.libro(x)>] -> 'libros'\n",
      "VCOP[NUM=sg] -> 'es'|'era'|'fue'\n",
      "VCOP[NUM=pl] -> 'son'|'eran'|'fueron'\n",
      "VCOP[NUM=sg] -> 'está'|'estaba'|'estuvo'\n",
      "VCOP[NUM=pl] -> 'están'|'estaban'|'estuvieron'\n",
      "IV[NUM=sg,SEM=<\\x.fumar(x)>,TNS=pres] -> 'fuma'\n",
      "IV[NUM=pl,SEM=<\\x.fumar(x)>,TNS=pres] -> 'fuman'\n",
      "IV[NUM=sg,SEM=<\\x.caminar(x)>,TNS=pres] -> 'camina'\n",
      "IV[NUM=pl,SEM=<\\x.caminar(x)>,TNS=pres] -> 'caminan'\n",
      "IV[NUM=sg,SEM=<\\x.correr(x)>,TNS=pres] -> 'corre'\n",
      "IV[NUM=pl,SEM=<\\x.correr(x)>,TNS=pres] -> 'corren'\n",
      "IV[NUM=sg,SEM=<\\x.correr(x)>,TNS=pas] -> 'corrió'\n",
      "IV[NUM=pl,SEM=<\\x.correr(x)>,TNS=pas] -> 'corrieron'\n",
      "IV[NUM=sg,SEM=<\\x.explotar(x)>,TNS=pres] -> 'explota'\n",
      "IV[NUM=pl,SEM=<\\x.explotar(x)>,TNS=pres] -> 'explotan'\n",
      "IV[NUM=sg,SEM=<\\x.explotar(x)>,TNS=pas] -> 'explotó'\n",
      "IV[NUM=pl,SEM=<\\x.explotar(x)>,TNS=pas] -> 'explotaron'\n",
      "TV[NUM=sg,SEM=<\\X x.X(\\y.mirar(x,y))>,TNS=pres] -> 'mira'\n",
      "TV[NUM=pl,SEM=<\\X x.X(\\y.mirar(x,y))>,TNS=pres] -> 'miran'\n",
      "TV[NUM=sg,SEM=<\\X x.X(\\y.romper(x,y))>,TNS=pres] -> 'rompe'\n",
      "TV[NUM=pl,SEM=<\\X x.X(\\y.romper(x,y))>,TNS=pres] -> 'rompen'\n",
      "TV[NUM=sg,SEM=<\\X x.X(\\y.morder(x,y))>,TNS=pres] -> 'muerde'\n",
      "TV[NUM=pl,SEM=<\\X x.X(\\y.morder(x,y))>,TNS=pres] -> 'muerden'\n",
      "DTV[NUM=sg,SEM=<\\Y X x.X(\\z.Y(\\y.dar(x,y,z)))>,TNS=pres] -> 'da'\n",
      "DTV[NUM=pl,SEM=<\\Y X x.X(\\z.Y(\\y.dar(x,y,z)))>,TNS=pres] -> 'dan'\n",
      "DTV[NUM=sg,SEM=<\\Y X x.X(\\z.Y(\\y.dar(x,y,z)))>,TNS=pas] -> 'dio'\n",
      "DTV[NUM=pl,SEM=<\\Y X x.X(\\z.Y(\\y.dar(x,y,z)))>,TNS=pas] -> 'dieron'\n",
      "DTV[NUM=sg,SEM=<\\Y X x.X(\\z.Y(\\y.entregar(x,y,z)))>,TNS=pres] -> 'entrega'\n",
      "DTV[NUM=pl,SEM=<\\Y X x.X(\\z.Y(\\y.entregar(x,y,z)))>,TNS=pres] -> 'entregan'\n",
      "DTV[NUM=sg,SEM=<\\Y X x.X(\\z.Y(\\y.entregar(x,y,z)))>,TNS=pas] -> 'entregó'\n",
      "DTV[NUM=pl,SEM=<\\Y X x.X(\\z.Y(\\y.entregar(x,y,z)))>,TNS=pas] -> 'entregaron'\n",
      "DTV[NUM=sg,SEM=<\\Y X x.X(\\z.Y(\\y.enviar(x,y,z)))>,TNS=pres] -> 'envía'\n",
      "DTV[NUM=pl,SEM=<\\Y X x.X(\\z.Y(\\y.enviar(x,y,z)))>,TNS=pres] -> 'envían'\n",
      "DTV[NUM=sg,SEM=<\\Y X x.X(\\z.Y(\\y.enviar(x,y,z)))>,TNS=pas] -> 'envió'\n",
      "DTV[NUM=pl,SEM=<\\Y X x.X(\\z.Y(\\y.enviar(x,y,z)))>,TNS=pas] -> 'enviaron'\n",
      "P[+a] -> 'a'\n",
      "A[NUM=sg,GEN=fem,SEM=<\\x.ocupado(x)>] -> 'ocupada'\n",
      "A[NUM=pl,GEN=fem,SEM=<\\x.ocupado(x)>] -> 'ocupadas'\n",
      "A[NUM=sg,GEN=masc,SEM=<\\x.ocupado(x)>] -> 'ocupado'\n",
      "A[NUM=pl,GEN=masc,SEM=<\\x.ocupado(x)>] -> 'ocupados'\n",
      "A[NUM=sg,GEN=fem,SEM=<\\x.cansado(x)>] -> 'cansada'\n",
      "A[NUM=pl,GEN=fem,SEM=<\\x.cansado(x)>] -> 'cansadas'\n",
      "A[NUM=sg,GEN=masc,SEM=<\\x.cansado(x)>] -> 'cansado'\n",
      "A[NUM=pl,GEN=masc,SEM=<\\x.cansado(x)>] -> 'cansados'\n",
      "A[NUM=sg,GEN=fem,SEM=<\\x.ocupado(x)>] -> 'fumada'\n",
      "A[NUM=pl,GEN=fem,SEM=<\\x.ocupado(x)>] -> 'fumadas'\n",
      "A[NUM=sg,GEN=masc,SEM=<\\x.ocupado(x)>] -> 'fumado'\n",
      "A[NUM=pl,GEN=masc,SEM=<\\x.ocupado(x)>] -> 'fumados'\n"
     ]
    }
   ],
   "source": [
    "nltk.data.show_cfg('pruebasemantica.fcfg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S[SEM=<exists x.(unico_ind_relevante_en_contexto(x) & globo(x) & fumar(x))>]\n",
      "  (NP[GEN='masc', NUM='sg', SEM=<\\Q.exists x.(unico_ind_relevante_en_contexto(x) & globo(x) & Q(x))>]\n",
      "    (Det[GEN='masc', NUM='sg', SEM=<\\P Q.exists x.(unico_ind_relevante_en_contexto(x) & P(x) & Q(x))>]\n",
      "      el)\n",
      "    (Nom[GEN='masc', NUM='sg', SEM=<\\x.globo(x)>]\n",
      "      (N[GEN='masc', NUM='sg', SEM=<\\x.globo(x)>] globo)))\n",
      "  (VP[NUM='sg', SEM=<\\x.fumar(x)>]\n",
      "    (IV[NUM='sg', SEM=<\\x.fumar(x)>, TNS='pres'] fuma)))\n"
     ]
    }
   ],
   "source": [
    "sents = ['el globo fuma']\n",
    "grammar = 'pruebasemantica.fcfg'\n",
    "for results in nltk.interpret_sents(sents, grammar):\n",
    "    for (synrep, semrep) in results:\n",
    "             print(synrep)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Los postulados de significado\n",
    "\n",
    "Los postulados de significado permiten definir relaciones de sinonimia entre distintos predicados que no están léxicamente relacionados. Algunos ejemplos clásicos son:\n",
    "\n",
    "- ser soltero = ser no casado\n",
    "- ser oculista = ser médico de ojos\n",
    "- patear = pegar con el pie\n",
    "\n",
    "El siguiente es un ejemplo en prolog extraído de Profglot:\n",
    "\n",
    "`mean(eng, [[kiss], [act],[[[anim],X1,[ag]],[[anim],X2,[pt]]]],\n",
    "[_,[[touch],[act],[[[anim],X1,[ag]],[[concr],X2,[pt]]]],\n",
    "[_,[[idiom],'the lips',[instr]],_,J]).`\n",
    "\n",
    "No encontré que se usen en Python (no le puse toda la onda tampoco)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Semántica eventiva\n",
    "\n",
    "Un tipo de semántica formal que hoy ha ganado mucha popularidad es la semántica eventiva. La semántica eventiva concibe el significado de las oraciones como cuantificación sobre eventos: \n",
    "\n",
    "- Juan le dio ayer el libro a Pedro en la casa.\n",
    "- Existe un e tal que Agente(e, Juan) & Tema(e, el libro) & Meta(e, Pedro) & en(e, la casa) & Pasado(e)\n",
    "\n",
    "La semántica neodavidsoniana permite dispensar de grandes listas de subclases (verbos transitivos, verbos intransitivos, verbos ditransitivos, verbos bivalentes, verbos impersonales, verbos que toman distintos tipos de sintagmas preposicionales) y simplificar, en consecuencia, el léxico. Esto se hace al costo de dar una denotación más compleja a las entradas léxicas (que sin embargo, se puede automatizar si se tienen listas léxicas como las de freeling) y a las reglas de reescritura. Este tipo de enfoques propenden a sobregenerar, pero, naturalmente, este no es un problema si lo que nos interesa es parsear oraciones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S[SEM=<(exists e.agente(e,cata) & dar(e) & pasado(e) & tema(e,ficciones) & meta(e,chafa))>]\n",
      "  (NP[+ANIM, GEN='fem', NUM='sg', SEM=<\\P.P(cata)>]\n",
      "    (PropN[+ANIM, GEN='fem', NUM='sg', SEM=<\\P.P(cata)>] Cata))\n",
      "  (VP[NUM='sg', SEM=<\\e.(dar(e) & pasado(e) & tema(e,ficciones) & meta(e,chafa))>]\n",
      "    (V[NUM='sg', SEM=<\\e.(dar(e) & pasado(e))>, TNS='pas'] dio)\n",
      "    (NP[-ANIM, GEN='masc', NUM='sg', SEM=<\\P.P(ficciones)>]\n",
      "      (PropN[-ANIM, GEN='masc', NUM='sg', SEM=<\\P.P(ficciones)>]\n",
      "        Ficciones))\n",
      "    (PP[+A, SEM=<\\P.P(chafa)>]\n",
      "      (P[+a] a)\n",
      "      (NP[+ANIM, GEN='masc', NUM='sg', SEM=<\\P.P(chafa)>]\n",
      "        (PropN[+ANIM, GEN='masc', NUM='sg', SEM=<\\P.P(chafa)>] Chafa)))))\n"
     ]
    }
   ],
   "source": [
    "#import nltk\n",
    "#sents = ['Cata fuma']\n",
    "#sents = ['Fede leyó Ficciones']\n",
    "sents = ['Cata dio Ficciones a Chafa']\n",
    "grammar = 'semantica_eventiva_base.fcfg'\n",
    "for results in nltk.interpret_sents(sents, grammar):\n",
    "    for (synrep, semrep) in results:\n",
    "             print(synrep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
